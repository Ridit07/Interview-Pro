{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12500,
          "databundleVersionId": 1375107,
          "sourceType": "competition"
        },
        {
          "sourceId": 11650,
          "sourceType": "datasetVersion",
          "datasetId": 8327
        },
        {
          "sourceId": 19053,
          "sourceType": "datasetVersion",
          "datasetId": 14154
        },
        {
          "sourceId": 127694,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 107533,
          "modelId": 131881
        },
        {
          "sourceId": 127729,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 107565,
          "modelId": 131912
        }
      ],
      "dockerImageVersionId": 24141,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preface"
      ],
      "metadata": {
        "id": "XYHTzlzYT-G-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Utility functions"
      ],
      "metadata": {
        "id": "wH094lxFT-HA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import random\n",
        "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
        "from keras.preprocessing import text, sequence\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:21.318791Z",
          "iopub.execute_input": "2024-11-03T18:54:21.319108Z",
          "iopub.status.idle": "2024-11-03T18:54:23.341292Z",
          "shell.execute_reply.started": "2024-11-03T18:54:21.319044Z",
          "shell.execute_reply": "2024-11-03T18:54:23.340530Z"
        },
        "trusted": true,
        "id": "FMoq88jHT-HA",
        "outputId": "7de602eb-a839-4f12-e0ba-a8a5f4215668"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Using TensorFlow backend.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:27.757561Z",
          "iopub.execute_input": "2024-11-03T18:54:27.757927Z",
          "iopub.status.idle": "2024-11-03T18:54:27.771736Z",
          "shell.execute_reply.started": "2024-11-03T18:54:27.757870Z",
          "shell.execute_reply": "2024-11-03T18:54:27.770779Z"
        },
        "trusted": true,
        "id": "jUdUIO4QT-HB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "CRAWL_EMBEDDING_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n",
        "GLOVE_EMBEDDING_PATH = '../input/glove840b300dtxt/glove.840B.300d.txt'\n",
        "NUM_MODELS = 2\n",
        "LSTM_UNITS = 128\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
        "MAX_LEN = 220"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:28.190321Z",
          "iopub.execute_input": "2024-11-03T18:54:28.190629Z",
          "iopub.status.idle": "2024-11-03T18:54:28.195082Z",
          "shell.execute_reply.started": "2024-11-03T18:54:28.190584Z",
          "shell.execute_reply": "2024-11-03T18:54:28.194142Z"
        },
        "trusted": true,
        "id": "fpoMLa_RT-HC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coefs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def load_embeddings(path):\n",
        "    with open(path) as f:\n",
        "        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n",
        "\n",
        "def build_matrix(word_index, path):\n",
        "    embedding_index = load_embeddings(path)\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "    unknown_words = []\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        try:\n",
        "            embedding_matrix[i] = embedding_index[word]\n",
        "        except KeyError:\n",
        "            unknown_words.append(word)\n",
        "    return embedding_matrix, unknown_words"
      ],
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:28.880844Z",
          "iopub.execute_input": "2024-11-03T18:54:28.881150Z",
          "iopub.status.idle": "2024-11-03T18:54:28.888250Z",
          "shell.execute_reply.started": "2024-11-03T18:54:28.881094Z",
          "shell.execute_reply": "2024-11-03T18:54:28.887128Z"
        },
        "trusted": true,
        "id": "X3AkV6fgT-HC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def train_model(model, train, test, loss_fn, output_dim, lr=0.001,\n",
        "                batch_size=512, n_epochs=4,\n",
        "                enable_checkpoint_ensemble=True):\n",
        "    param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n",
        "    optimizer = torch.optim.Adam(param_lrs, lr=lr)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "    all_test_preds = []\n",
        "    checkpoint_weights = [2 ** epoch for epoch in range(n_epochs)]\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "\n",
        "        for data in tqdm(train_loader, disable=False):\n",
        "            x_batch = data[:-1]\n",
        "            y_batch = data[-1]\n",
        "\n",
        "            y_pred = model(*x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        test_preds = np.zeros((len(test), output_dim))\n",
        "\n",
        "        for i, x_batch in enumerate(test_loader):\n",
        "            y_pred = sigmoid(model(*x_batch).detach().cpu().numpy())\n",
        "\n",
        "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred\n",
        "\n",
        "        all_test_preds.append(test_preds)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "              epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "\n",
        "    if enable_checkpoint_ensemble:\n",
        "        test_preds = np.average(all_test_preds, weights=checkpoint_weights, axis=0)\n",
        "    else:\n",
        "        test_preds = all_test_preds[-1]\n",
        "\n",
        "    return test_preds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:29.227505Z",
          "iopub.execute_input": "2024-11-03T18:54:29.227790Z",
          "iopub.status.idle": "2024-11-03T18:54:29.240663Z",
          "shell.execute_reply.started": "2024-11-03T18:54:29.227748Z",
          "shell.execute_reply": "2024-11-03T18:54:29.239595Z"
        },
        "trusted": true,
        "id": "-lLpRf0JT-HD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class SpatialDropout(nn.Dropout2d):\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
        "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
        "        x = x.squeeze(2)  # (N, T, K)\n",
        "        return x\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, embedding_matrix, num_aux_targets):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        embed_size = embedding_matrix.shape[1]\n",
        "\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.embedding_dropout = SpatialDropout(0.3)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
        "        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
        "\n",
        "        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n",
        "        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = self.embedding_dropout(h_embedding)\n",
        "\n",
        "        h_lstm1, _ = self.lstm1(h_embedding)\n",
        "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
        "\n",
        "        # global average pooling\n",
        "        avg_pool = torch.mean(h_lstm2, 1)\n",
        "        # global max pooling\n",
        "        max_pool, _ = torch.max(h_lstm2, 1)\n",
        "\n",
        "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
        "        h_conc_linear1  = F.relu(self.linear1(h_conc))\n",
        "        h_conc_linear2  = F.relu(self.linear2(h_conc))\n",
        "\n",
        "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
        "\n",
        "        result = self.linear_out(hidden)\n",
        "        aux_result = self.linear_aux_out(hidden)\n",
        "        out = torch.cat([result, aux_result], 1)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:29.857389Z",
          "iopub.execute_input": "2024-11-03T18:54:29.857675Z",
          "iopub.status.idle": "2024-11-03T18:54:29.869279Z",
          "shell.execute_reply.started": "2024-11-03T18:54:29.857624Z",
          "shell.execute_reply": "2024-11-03T18:54:29.868570Z"
        },
        "trusted": true,
        "id": "qFWLa8GvT-HD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "    '''\n",
        "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
        "    '''\n",
        "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
        "    def clean_special_chars(text, punct):\n",
        "        for p in punct:\n",
        "            text = text.replace(p, ' ')\n",
        "        return text\n",
        "\n",
        "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
        "    return data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:37.250695Z",
          "iopub.execute_input": "2024-11-03T18:54:37.251004Z",
          "iopub.status.idle": "2024-11-03T18:54:37.256052Z",
          "shell.execute_reply.started": "2024-11-03T18:54:37.250946Z",
          "shell.execute_reply": "2024-11-03T18:54:37.255064Z"
        },
        "trusted": true,
        "id": "s-9sRqJHT-HD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "NihBn2PmT-HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
        "test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n",
        "\n",
        "x_train = preprocess(train['comment_text'])\n",
        "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
        "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n",
        "x_test = preprocess(test['comment_text'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:54:38.887164Z",
          "iopub.execute_input": "2024-11-03T18:54:38.887726Z",
          "iopub.status.idle": "2024-11-03T18:55:35.374628Z",
          "shell.execute_reply.started": "2024-11-03T18:54:38.887671Z",
          "shell.execute_reply": "2024-11-03T18:55:35.373713Z"
        },
        "trusted": true,
        "id": "93hry00GT-HE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = None"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:55:51.322170Z",
          "iopub.execute_input": "2024-11-03T18:55:51.322552Z",
          "iopub.status.idle": "2024-11-03T18:55:51.326147Z",
          "shell.execute_reply.started": "2024-11-03T18:55:51.322466Z",
          "shell.execute_reply": "2024-11-03T18:55:51.325160Z"
        },
        "trusted": true,
        "id": "F4KBJAsFT-HE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(list(x_train) + list(x_test))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T18:55:52.354986Z",
          "iopub.execute_input": "2024-11-03T18:55:52.355297Z",
          "iopub.status.idle": "2024-11-03T19:00:06.229773Z",
          "shell.execute_reply.started": "2024-11-03T18:55:52.355236Z",
          "shell.execute_reply": "2024-11-03T19:00:06.229073Z"
        },
        "trusted": true,
        "id": "MdrnTRsoT-HE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = max_features or len(tokenizer.word_index) + 1\n",
        "max_features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T19:00:17.863010Z",
          "iopub.execute_input": "2024-11-03T19:00:17.863277Z",
          "iopub.status.idle": "2024-11-03T19:00:17.869993Z",
          "shell.execute_reply.started": "2024-11-03T19:00:17.863237Z",
          "shell.execute_reply": "2024-11-03T19:00:17.869278Z"
        },
        "trusted": true,
        "id": "cNvFfKGNT-HF",
        "outputId": "d115db4c-d15f-4f31-f66d-2d092d24244f"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "327009"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "crawl_matrix, unknown_words_crawl = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\n",
        "print('n unknown words (crawl): ', len(unknown_words_crawl))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T19:00:19.480406Z",
          "iopub.execute_input": "2024-11-03T19:00:19.480685Z",
          "iopub.status.idle": "2024-11-03T19:04:47.225249Z",
          "shell.execute_reply.started": "2024-11-03T19:00:19.480643Z",
          "shell.execute_reply": "2024-11-03T19:04:47.224580Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "ee06579f15b140ddaa026e4a58770aa2"
          ]
        },
        "id": "SLClsoX1T-HF",
        "outputId": "85480590-8eca-4c64-a6fb-c5a5acbca755"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee06579f15b140ddaa026e4a58770aa2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nn unknown words (crawl):  173678\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "glove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\n",
        "print('n unknown words (glove): ', len(unknown_words_glove))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T19:06:18.563700Z",
          "iopub.execute_input": "2024-11-03T19:06:18.563985Z",
          "iopub.status.idle": "2024-11-03T19:11:16.001213Z",
          "shell.execute_reply.started": "2024-11-03T19:06:18.563944Z",
          "shell.execute_reply": "2024-11-03T19:11:16.000507Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "a36324e981e646138d8c224294415ce0"
          ]
        },
        "id": "Vk_5pnI8T-HF",
        "outputId": "aa77c3ee-29da-4344-e702-a58874329b80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a36324e981e646138d8c224294415ce0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nn unknown words (glove):  170383\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.concatenate([crawl_matrix, glove_matrix], axis=-1)\n",
        "embedding_matrix.shape\n",
        "\n",
        "del crawl_matrix\n",
        "del glove_matrix\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T19:15:02.916083Z",
          "iopub.execute_input": "2024-11-03T19:15:02.916394Z",
          "iopub.status.idle": "2024-11-03T19:15:04.342231Z",
          "shell.execute_reply.started": "2024-11-03T19:15:02.916326Z",
          "shell.execute_reply": "2024-11-03T19:15:04.341490Z"
        },
        "trusted": true,
        "id": "oTYW3Y6tT-HF",
        "outputId": "d34b13ea-ef5b-439d-a116-5a6a26191057"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_torch = torch.tensor(x_train, dtype=torch.long).cuda()\n",
        "x_test_torch = torch.tensor(x_test, dtype=torch.long).cuda()\n",
        "y_train_torch = torch.tensor(np.hstack([y_train[:, np.newaxis], y_aux_train]), dtype=torch.float32).cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T19:15:07.178964Z",
          "iopub.execute_input": "2024-11-03T19:15:07.180391Z",
          "iopub.status.idle": "2024-11-03T19:15:16.423767Z",
          "shell.execute_reply.started": "2024-11-03T19:15:07.179319Z",
          "shell.execute_reply": "2024-11-03T19:15:16.423066Z"
        },
        "trusted": true,
        "id": "ApUUxErmT-HG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "nHUkdnuST-HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = data.TensorDataset(x_train_torch, y_train_torch)\n",
        "test_dataset = data.TensorDataset(x_test_torch)\n",
        "\n",
        "all_test_preds = []\n",
        "\n",
        "for model_idx in range(NUM_MODELS):\n",
        "    print('Model ', model_idx)\n",
        "    seed_everything(1234 + model_idx)\n",
        "\n",
        "    model = NeuralNet(embedding_matrix, y_aux_train.shape[-1])\n",
        "    model.cuda()\n",
        "\n",
        "    test_preds = train_model(model, train_dataset, test_dataset, output_dim=y_train_torch.shape[-1],\n",
        "                             loss_fn=nn.BCEWithLogitsLoss(reduction='mean'))\n",
        "    all_test_preds.append(test_preds)\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T19:15:34.108713Z",
          "iopub.execute_input": "2024-11-03T19:15:34.108984Z",
          "iopub.status.idle": "2024-11-03T21:13:27.441504Z",
          "shell.execute_reply.started": "2024-11-03T19:15:34.108944Z",
          "shell.execute_reply": "2024-11-03T21:13:27.440177Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "f3096238b0b147998eeed8c5dc7aa898",
            "02cd855c485c4bb388805300076b2528",
            "21323a912ea042aea55871212445359d",
            "5f5292faa01441b7ae993c98fb5fc07c",
            "38966de424d045dfa671c1763b279bf1",
            "815256afb44747d98246a73a107ffea6",
            "95a21878950b4642a605ac1c3067383c"
          ]
        },
        "id": "VRzLb6bmT-HG",
        "outputId": "d6c469a9-9d31-403f-ba32-6a44cdfd3fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model  0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=3526), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3096238b0b147998eeed8c5dc7aa898"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/4 \t loss=0.1094 \t time=1032.40s\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=3526), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02cd855c485c4bb388805300076b2528"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nEpoch 2/4 \t loss=0.1034 \t time=1037.33s\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=3526), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21323a912ea042aea55871212445359d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nEpoch 3/4 \t loss=0.1019 \t time=1037.52s\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=3526), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f5292faa01441b7ae993c98fb5fc07c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nEpoch 4/4 \t loss=0.1010 \t time=1037.62s\n\nModel  1\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=3526), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38966de424d045dfa671c1763b279bf1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/4 \t loss=0.1096 \t time=1035.39s\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=3526), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "815256afb44747d98246a73a107ffea6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nEpoch 2/4 \t loss=0.1035 \t time=1036.52s\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=3526), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95a21878950b4642a605ac1c3067383c"
            }
          },
          "metadata": {}
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c46512a56759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     test_preds = train_model(model, train_dataset, test_dataset, output_dim=y_train_torch.shape[-1], \n\u001b[0;32m---> 14\u001b[0;31m                              loss_fn=nn.BCEWithLogitsLoss(reduction='mean'))\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mall_test_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e9e95d24d263>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train, test, loss_fn, output_dim, lr, batch_size, n_epochs, enable_checkpoint_ensemble)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(model, data_loader, tokenizer, loss_fn=None):\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            x_batch = batch[:-1]  # Extract inputs\n",
        "            y_batch = batch[-1]  # Extract labels\n",
        "\n",
        "            # Forward pass to get predictions\n",
        "            y_pred = model(*x_batch)\n",
        "            y_pred = sigmoid(y_pred.detach().cpu().numpy())  # Apply sigmoid to get probabilities\n",
        "            y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "            all_preds.append(y_pred_binary[:, 0])  # Append predictions\n",
        "            all_labels.append(y_batch[:, 0].cpu().numpy())  # Append true labels\n",
        "\n",
        "    # Concatenate all predictions and labels\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1\n",
        "    }\n",
        "\n",
        "    # Print metrics\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    data.TensorDataset(x_test_torch, y_train_torch[:, 0]),\n",
        "    batch_size=512,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "metrics = evaluate_model(model, test_loader, tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHtVIPz9Usag",
        "outputId": "d0928d2d-a247-471b-a371-45faf2729177"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Accuracy: 0.89\n",
            "Precision: 0.86\n",
            "Recall: 0.84\n",
            "F1-Score: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ndef save_model(model, file_name='/kaggle/working/model.pth'):\n",
        "    torch.save(model.state_dict(), file_name)\n",
        "save_model(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-05T14:32:11.655941Z",
          "iopub.execute_input": "2024-10-05T14:32:11.656235Z",
          "iopub.status.idle": "2024-10-05T14:32:12.929228Z",
          "shell.execute_reply.started": "2024-10-05T14:32:11.656190Z",
          "shell.execute_reply": "2024-10-05T14:32:12.928474Z"
        },
        "trusted": true,
        "id": "zhcZV85vT-HG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# After training each model, save it to /kaggle/working/\n",
        "for model_idx in range(NUM_MODELS):`\n",
        "    model_path = f\"/kaggle/working/model_{model_idx}.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Model {model_idx} saved to {model_path}\")\n"
      ],
      "metadata": {
        "id": "b93myF9YT-HG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path, embedding_matrix, num_aux_targets):\n",
        "    model = NeuralNet(embedding_matrix, num_aux_targets)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    return model\n",
        "\n",
        "# Load a specific model\n",
        "model_idx = 0  # Load model_0 as an example\n",
        "model_path = f\"/kaggle/input/modelb/pytorch/default/1/model.pth\"\n",
        "model = load_model(model_path, embedding_matrix, y_aux_train.shape[-1])\n",
        "model.cuda()  # Move model to GPU if available\n",
        "\n",
        "# Function to preprocess and predict a sentence\n",
        "from keras.preprocessing.sequence import pad_sequences  # Ensure this import is present\n",
        "\n",
        "def predict_sentence(sentence, model, tokenizer, max_len=MAX_LEN):\n",
        "    # Preprocess the sentence\n",
        "    sentence = preprocess(pd.Series([sentence]))\n",
        "    sequence = tokenizer.texts_to_sequences(sentence)\n",
        "\n",
        "    # Pad the sequence correctly using keras' pad_sequences\n",
        "    sequence = pad_sequences(sequence, maxlen=max_len)  # Correct usage here\n",
        "    sequence = torch.tensor(sequence, dtype=torch.long).cuda()  # Convert to tensor and move to GPU\n",
        "\n",
        "    # Run the model to get the predictions\n",
        "    with torch.no_grad():\n",
        "        preds = model(sequence)\n",
        "        preds = sigmoid(preds.cpu().numpy())\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "\n",
        "# Example sentence for prediction\n",
        "def label_predictions(prediction):\n",
        "    # Extract individual values for readability\n",
        "    toxicity = prediction[0][0]\n",
        "    severe_toxicity = prediction[0][1]\n",
        "    obscene = prediction[0][2]\n",
        "    identity_attack = prediction[0][3]\n",
        "    insult = prediction[0][4]\n",
        "    threat = prediction[0][5]\n",
        "\n",
        "    # Print each prediction with labels\n",
        "    print(f\"Toxicity: {toxicity}\")\n",
        "    print(f\"Severe Toxicity: {severe_toxicity}\")\n",
        "    print(f\"Obscene: {obscene}\")\n",
        "    print(f\"Identity Attack: {identity_attack}\")\n",
        "    print(f\"Insult: {insult}\")\n",
        "    print(f\"Threat: {threat}\")\n",
        "\n",
        "# Example sentence for prediction\n",
        "sentence = \"Vishav is a piece of shit.\"\n",
        "prediction = predict_sentence(sentence, model, tokenizer)\n",
        "label_predictions(prediction)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T21:13:35.332863Z",
          "iopub.execute_input": "2024-11-03T21:13:35.333200Z",
          "iopub.status.idle": "2024-11-03T21:13:42.998712Z",
          "shell.execute_reply.started": "2024-11-03T21:13:35.333121Z",
          "shell.execute_reply": "2024-11-03T21:13:42.997987Z"
        },
        "trusted": true,
        "id": "q1NXIRf2T-HG",
        "outputId": "828c21ee-8f33-469a-dcfb-f5d496f43ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Toxicity: 0.9995326995849609\nSevere Toxicity: 0.9278066754341125\nObscene: 0.152074933052063\nIdentity Attack: 0.8808927536010742\nInsult: 0.024855386465787888\nThreat: 0.7616588473320007\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the tokenizer to a file\n",
        "with open('/kaggle/working/tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"Tokenizer saved as 'tokenizer.pkl'\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T21:22:39.990049Z",
          "iopub.execute_input": "2024-11-03T21:22:39.990550Z",
          "iopub.status.idle": "2024-11-03T21:22:40.455088Z",
          "shell.execute_reply.started": "2024-11-03T21:22:39.990297Z",
          "shell.execute_reply": "2024-11-03T21:22:40.454017Z"
        },
        "trusted": true,
        "id": "xqDvsamjT-HH",
        "outputId": "70e03451-4c48-46a3-db4d-93debfa728b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Tokenizer saved as 'tokenizer.pkl'\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the embedding matrix to a file (e.g., as a .npy file)\n",
        "np.save('/kaggle/working/embedding_matrix.npy', embedding_matrix)\n",
        "\n",
        "print(\"Embedding matrix saved successfully!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T21:23:42.020213Z",
          "iopub.execute_input": "2024-11-03T21:23:42.020577Z",
          "iopub.status.idle": "2024-11-03T21:23:43.317601Z",
          "shell.execute_reply.started": "2024-11-03T21:23:42.020522Z",
          "shell.execute_reply": "2024-11-03T21:23:43.316586Z"
        },
        "trusted": true,
        "id": "-_CQBtdNT-HH",
        "outputId": "c5ea1b7a-6b9d-40c2-ee97-e2fee17f00fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Embedding matrix saved successfully!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embedding matrix from the saved .npy file\n",
        "import numpy as np\n",
        "embedding_matrix = np.load('/kaggle/input/emd/other/default/1/embedding_matrix.npy')\n",
        "\n",
        "print(\"Embedding matrix loaded successfully!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-05T16:04:17.799156Z",
          "iopub.execute_input": "2024-10-05T16:04:17.799464Z",
          "iopub.status.idle": "2024-10-05T16:04:26.729477Z",
          "shell.execute_reply.started": "2024-10-05T16:04:17.799420Z",
          "shell.execute_reply": "2024-10-05T16:04:26.728772Z"
        },
        "trusted": true,
        "id": "TJmgqUg9T-HH",
        "outputId": "7e4f5412-147b-4e45-d085-4187e393a28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Embedding matrix loaded successfully!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}